import torch
import torch.nn as nn
import torch.optim as optim
import torchvision # –û—Å—Ç–∞–≤–ª—è–µ–º —ç—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç
import torchvision.transforms as transforms
from torchvision.utils import save_image, make_grid
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os
import glob

# --- –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {DEVICE}") # –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ–¥–Ω–∞ –≤ –Ω–∞—á–∞–ª–µ

# –°–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è (Learning Rates)
LEARNING_RATE_G = 2e-4  # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.0002) –û–±—ã—á–Ω–æ 2e-4
LEARNING_RATE_D = 1e-5  # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.0001 - –º–µ–¥–ª–µ–Ω–Ω–µ–µ) –û–±—ã—á–Ω–æ 2e-4

BATCH_SIZE = 64      # –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö (–ø–æ–¥–±–µ—Ä–∏ –ø–æ–¥ —Å–≤–æ—é VRAM, –º–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å 32 –∏–ª–∏ 64)
IMAGE_SIZE = 64      # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 64x64)
CHANNELS_IMG = 3     # –ö–∞–Ω–∞–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (3 –¥–ª—è RGB, 1 –¥–ª—è grayscale)
NOISE_DIM = 100      # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ —à—É–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
NUM_EPOCHS = 10000    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è (–ø–æ–¥–±–∏—Ä–∞–π —Å–∞–º)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è
SMOOTH_REAL_LABEL = 0.8 # –ú–µ—Ç–∫–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–≤–º–µ—Å—Ç–æ 1.0) —Å 0.9 –¥–æ 0.8 –ø–æ–º–µ–Ω—è–ª
DISC_UPDATE_INTERVAL = 4 # –û–±–Ω–æ–≤–ª—è—Ç—å –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –∫–∞–∂–¥—ã–π N-–π —à–∞–≥ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑ –≤ 2 —à–∞–≥–∞) –ë–´–õ–û 2 –ü–û–°–¢–ê–í–ò–õ 4 –ß–¢–û–ë –ó–ê–ú–ï–î–õ–ò–¢–¨ –î–ò–°–ö–†–ò–ú–ò–ù–ê–¢–û–† –í–ï–†–ù–£–¢–¨ –ü–û–¢–û–ú

# –ü—É—Ç–∏
DATASET_PATH = "dataset/mydata" # –£–ö–ê–ñ–ò –ü–£–¢–¨ –ö –ü–ê–ü–ö–ï –° –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø–ú–ò –≤ dataset
OUTPUT_PATH = "output_images"
CHECKPOINT_SAVE_INTERVAL = 20 # –°–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö

# --- –ö–ª–∞—Å—Å –¥–ª—è —Å–≤–æ–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ ---
class CustomImageDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã jpg, png, jpeg (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã)
        self.image_paths = glob.glob(os.path.join(image_dir, "*.jpg")) + \
                           glob.glob(os.path.join(image_dir, "*.png")) + \
                           glob.glob(os.path.join(image_dir, "*.jpeg"))
        if not self.image_paths:
            raise Exception(f"No images found in {image_dir}. Check the DATASET_PATH and image formats.")
        print(f"Found {len(self.image_paths)} images in {image_dir}")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        try:
            image = Image.open(img_path).convert("RGB") # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB
        except Exception as e:
            print(f"Warning: Could not load image {img_path}: {e}. Trying next.")
            # –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–∫–∏: –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –≤–∞–ª–∏–¥–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
            # –≠—Ç–æ –Ω–µ –∏–¥–µ–∞–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±, –Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã...
            # –í –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö –º–æ–∂–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫–∏ –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—å
            next_idx = (idx + 1) % len(self.image_paths) # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É, –∑–∞—Ü–∏–∫–ª–∏–≤–∞—è—Å—å
            if next_idx == idx: # –ï—Å–ª–∏ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –±–∏—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                 raise Exception(f"Single image in dataset is corrupted: {img_path}")
            return self.__getitem__(next_idx)


        if self.transform:
            image = self.transform(image)
        return image

# --- –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä ---
class Generator(nn.Module):
    def __init__(self, noise_dim, channels_img, features_g):
        super(Generator, self).__init__()
        self.net = nn.Sequential(
            # –í—Ö–æ–¥: N x noise_dim x 1 x 1
            self._block(noise_dim, features_g * 16, 4, 1, 0),  # N x f_g*16 x 4 x 4
            self._block(features_g * 16, features_g * 8, 4, 2, 1), # N x f_g*8 x 8 x 8
            self._block(features_g * 8, features_g * 4, 4, 2, 1), # N x f_g*4 x 16 x 16
            self._block(features_g * 4, features_g * 2, 4, 2, 1), # N x f_g*2 x 32 x 32
            nn.ConvTranspose2d(
                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1
            ), # N x channels_img x 64 x 64
            nn.Tanh() # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤—ã—Ö–æ–¥ –≤ [-1, 1]
        )

    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
        return nn.Sequential(
            nn.ConvTranspose2d(
                in_channels, out_channels, kernel_size, stride, padding, bias=False,
            ),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(True),
        )

    def forward(self, x):
        return self.net(x)

# --- –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä ---
class Discriminator(nn.Module):
    def __init__(self, channels_img, features_d):
        super(Discriminator, self).__init__()
        self.net = nn.Sequential(
            # –í—Ö–æ–¥: N x channels_img x 64 x 64
            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1), # N x f_d x 32 x 32
            nn.LeakyReLU(0.2, inplace=True),
            self._block(features_d, features_d * 2, 4, 2, 1),    # N x f_d*2 x 16 x 16
            self._block(features_d * 2, features_d * 4, 4, 2, 1),  # N x f_d*4 x 8 x 8
            self._block(features_d * 4, features_d * 8, 4, 2, 1),  # N x f_d*8 x 4 x 4
            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=1, padding=0), # N x 1 x 1 x 1
            nn.Sigmoid() # –í—ã—Ö–æ–¥: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (–æ–¥–Ω–æ —á–∏—Å–ª–æ)
        )

    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
        return nn.Sequential(
            nn.Conv2d(
                in_channels, out_channels, kernel_size, stride, padding, bias=False,
            ),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.2, inplace=True),
        )

    def forward(self, x):
        return self.net(x).view(-1) # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ (—Ö–æ—Ä–æ—à–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞) ---
def initialize_weights(model):
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):
            nn.init.normal_(m.weight.data, 0.0, 0.02)
            if m.bias is not None: # BatchNorm –Ω–µ –∏–º–µ–µ—Ç bias –µ—Å–ª–∏ affine=False, ConvTranspose2d –º–æ–∂–µ—Ç –∏–º–µ—Ç—å bias=False
                 nn.init.constant_(m.bias.data, 0)


# --- –ì–ª–∞–≤–Ω—ã–π –±–ª–æ–∫ ---
if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    if not os.path.exists(OUTPUT_PATH):
        os.makedirs(OUTPUT_PATH)
    if not os.path.exists(DATASET_PATH):
        print(f"Error: Dataset path {DATASET_PATH} does not exist. Please create it and put your images there.")
        exit()
    elif not os.path.exists(os.path.join(DATASET_PATH)) or not any(fname.lower().endswith(('.png', '.jpg', '.jpeg')) for fname in os.listdir(DATASET_PATH)):
        print(f"Error: Dataset path {DATASET_PATH} is empty or contains no images. Please put your images there.")
        exit()


    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    transform = transforms.Compose([
        transforms.Resize(IMAGE_SIZE),
        transforms.CenterCrop(IMAGE_SIZE),
        transforms.ToTensor(), # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç PIL Image (H x W x C) –≤ —Ç–µ–Ω–∑–æ—Ä (C x H x W) –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤ [0, 1]
        transforms.Normalize(
            [0.5 for _ in range(CHANNELS_IMG)], # –°—Ä–µ–¥–Ω–µ–µ
            [0.5 for _ in range(CHANNELS_IMG)]  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
        ) # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤ [-1, 1]
    ])
    
    try:
        dataset = CustomImageDataset(image_dir=DATASET_PATH, transform=transform)
        if len(dataset) == 0: # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –µ—Å–ª–∏ CustomImageDataset –Ω–µ –≤—ã–∑–≤–∞–ª –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
            print(f"No images were loaded from {DATASET_PATH}. Ensure images are present and paths are correct.")
            exit()
    except Exception as e:
        print(f"Error loading dataset: {e}")
        exit()

    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True) # drop_last=True –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å, –µ—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ç—á —Å–ª–∏—à–∫–æ–º –º–∞–ª

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –ó–∞–≥—Ä—É–∑–∫–∞ –ú–æ–¥–µ–ª–µ–π –∏ –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ ---
    START_EPOCH = 0
    CHECKPOINT_LOAD_PATH = f"{OUTPUT_PATH}/checkpoint_latest.pth" 

    gen = Generator(NOISE_DIM, CHANNELS_IMG, features_g=64).to(DEVICE)
    disc = Discriminator(CHANNELS_IMG, features_d=64).to(DEVICE)
    
    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE_G, betas=(0.5, 0.999))
    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE_D, betas=(0.5, 0.999)) # –ò—Å–ø–æ–ª—å–∑—É–µ–º LEARNING_RATE_D

    # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç
    if os.path.exists(CHECKPOINT_LOAD_PATH):
        print(f"üîÑ Loading checkpoint from {CHECKPOINT_LOAD_PATH}")
        try:
            checkpoint = torch.load(CHECKPOINT_LOAD_PATH, map_location=DEVICE)
            
            gen.load_state_dict(checkpoint['gen_state_dict'])
            disc.load_state_dict(checkpoint['disc_state_dict'])
            opt_gen.load_state_dict(checkpoint['opt_gen_state_dict'])
            opt_disc.load_state_dict(checkpoint['opt_disc_state_dict'])
            START_EPOCH = checkpoint['epoch']
            fixed_noise = checkpoint['fixed_noise'].to(DEVICE) 
            
            print(f"‚úÖ Checkpoint loaded. Resuming training from epoch {START_EPOCH}")
        except Exception as e:
            print(f"Error loading checkpoint: {e}. Starting from scratch.")
            START_EPOCH = 0 # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
            initialize_weights(gen)
            initialize_weights(disc)
            fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(DEVICE) # 32 –ø—Ä–∏–º–µ—Ä–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
    else:
        print("‚ÑπÔ∏è No checkpoint found. Starting training from scratch.")
        initialize_weights(gen)
        initialize_weights(disc)
        fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(DEVICE)


    criterion = nn.BCELoss() # Binary Cross Entropy

    print("üöÄ Starting Training...")
    # –û–±—â–∏–π —Å—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤ –¥–ª—è DISC_UPDATE_INTERVAL, –µ—Å–ª–∏ batch_idx —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π –±–∞—Ç—á
    # –ù–æ batch_idx –≤ DataLoader —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –Ω–∞–¥–æ –¥–ª—è —ç—Ç–æ–≥–æ –≤–Ω—É—Ç—Ä–∏ —ç–ø–æ—Ö–∏.
    
    for epoch in range(START_EPOCH, NUM_EPOCHS):
        for batch_idx, real_imgs in enumerate(dataloader):
            real_imgs = real_imgs.to(DEVICE)
            current_batch_size = real_imgs.shape[0] 

            if current_batch_size == 0: 
                continue

            # --- –û–±—É—á–µ–Ω–∏–µ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ ---
            # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ
            gen.zero_grad()
            noise_g = torch.randn(current_batch_size, NOISE_DIM, 1, 1).to(DEVICE) # –®—É–º –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
            fake_imgs_for_gen = gen(noise_g)
            # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ö–æ—á–µ—Ç, —á—Ç–æ–±—ã –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –¥—É–º–∞–ª, —á—Ç–æ —ç—Ç–æ –Ω–∞—Å—Ç–æ—è—â–∏–µ (–º–µ—Ç–∫–∞ 1.0 –∏–ª–∏ SMOOTH_REAL_LABEL)
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 1.0 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –æ–±—ã—á–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ, –¥–∞–∂–µ –µ—Å–ª–∏ –¥–ª—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
            label_real_for_gen = torch.full((current_batch_size,), 1.0, dtype=torch.float, device=DEVICE) 
            output_fake_for_gen = disc(fake_imgs_for_gen)
            loss_gen = criterion(output_fake_for_gen, label_real_for_gen) 
            loss_gen.backward()
            opt_gen.step()

            # --- –û–±—É—á–µ–Ω–∏–µ –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ ---
            # –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è —Ä–µ–∂–µ (–∫–∞–∂–¥—ã–π DISC_UPDATE_INTERVAL —à–∞–≥)
            if (batch_idx + 1) % DISC_UPDATE_INTERVAL == 0: # +1 —á—Ç–æ–±—ã –ø–µ—Ä–≤—ã–π –±–∞—Ç—á (batch_idx=0) —Ç–æ–∂–µ –º–æ–≥ –æ–±–Ω–æ–≤–∏—Ç—å—Å—è –µ—Å–ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª=1
                disc.zero_grad()

                # –ù–∞—Å—Ç–æ—è—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SMOOTH_REAL_LABEL)
                label_real = torch.full((current_batch_size,), SMOOTH_REAL_LABEL, dtype=torch.float, device=DEVICE)
                output_real = disc(real_imgs)
                loss_disc_real = criterion(output_real, label_real)

                # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —É–∂–µ —Å–¥–µ–ª–∞–ª —à–∞–≥, —Ç–∞–∫ —á—Ç–æ fake_imgs_for_gen —Å–≤–µ–∂–∏–µ)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º .detach() –¥–ª—è –ø–æ–¥–¥–µ–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞
                noise_d = torch.randn(current_batch_size, NOISE_DIM, 1, 1).to(DEVICE) # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—Ç –∂–µ —à—É–º, —á—Ç–æ –∏ –¥–ª—è G, –Ω–æ –ª—É—á—à–µ –Ω–æ–≤—ã–π
                # fake_imgs_for_disc = gen(noise_d).detach() # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –∏ –æ—Ç—Å–æ–µ–¥–∏–Ω—è–µ–º
                # –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ, —á—Ç–æ —É–∂–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è G, –Ω–æ –æ—Ç—Å–æ–µ–¥–∏–Ω—è–µ–º
                fake_imgs_for_disc = fake_imgs_for_gen.detach()


                label_fake = torch.full((current_batch_size,), 0.0, dtype=torch.float, device=DEVICE) # –ú–µ—Ç–∫–∏ "0" –¥–ª—è –ø–æ–¥–¥–µ–ª—å–Ω—ã—Ö
                output_fake_disc = disc(fake_imgs_for_disc)
                loss_disc_fake = criterion(output_fake_disc, label_fake)

                loss_disc = (loss_disc_real + loss_disc_fake) / 2
                loss_disc.backward()
                opt_disc.step()
            else:
                # –ï—Å–ª–∏ –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä, –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–ª–∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ —Ç–µ–∫—É—â–∏–µ –ø–æ—Ç–µ—Ä–∏ –±–µ–∑ backward
                # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º backward –∏ step
                # –ú–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å loss_disc –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –Ω–æ –±–µ–∑ backward()
                with torch.no_grad():
                    output_real_no_grad = disc(real_imgs)
                    loss_disc_real_no_grad = criterion(output_real_no_grad, torch.full((current_batch_size,), SMOOTH_REAL_LABEL, dtype=torch.float, device=DEVICE))
                    
                    # fake_imgs_for_disc_no_grad = gen(torch.randn(current_batch_size, NOISE_DIM, 1, 1).to(DEVICE)).detach()
                    fake_imgs_for_disc_no_grad = fake_imgs_for_gen.detach() # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ, —á—Ç–æ –∏ –¥–ª—è G

                    output_fake_disc_no_grad = disc(fake_imgs_for_disc_no_grad)
                    loss_disc_fake_no_grad = criterion(output_fake_disc_no_grad, torch.full((current_batch_size,), 0.0, dtype=torch.float, device=DEVICE))
                    loss_disc = (loss_disc_real_no_grad + loss_disc_fake_no_grad) / 2 # –≠—Ç–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

            # --- –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ---
            if batch_idx % 100 == 0: # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 100 –±–∞—Ç—á–µ–π
                print(
                    f"Epoch [{epoch+1}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \t"
                    f"Loss D: {loss_disc.item():.4f}, Loss G: {loss_gen.item():.4f}"
                )

                with torch.no_grad(): 
                    fake_samples = gen(fixed_noise)
                    img_grid_fake = make_grid(fake_samples, normalize=True)
                    save_image(img_grid_fake, f"{OUTPUT_PATH}/sample_epoch_{epoch+1}_batch_{batch_idx}.png")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ (–≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ –∏–ª–∏ –∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö)
        if (epoch + 1) % CHECKPOINT_SAVE_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:
            checkpoint = {
                'epoch': epoch + 1,
                'gen_state_dict': gen.state_dict(),
                'disc_state_dict': disc.state_dict(),
                'opt_gen_state_dict': opt_gen.state_dict(),
                'opt_disc_state_dict': opt_disc.state_dict(),
                'fixed_noise': fixed_noise,
                'loss_g': loss_gen.item(), 
                'loss_d': loss_disc.item()
            }
            torch.save(checkpoint, f"{OUTPUT_PATH}/checkpoint_epoch_{epoch+1}.pth")
            torch.save(checkpoint, f"{OUTPUT_PATH}/checkpoint_latest.pth") # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π
            print(f"‚úÖ Checkpoint saved at epoch {epoch+1}")

    print("üèÅ Training Finished!")